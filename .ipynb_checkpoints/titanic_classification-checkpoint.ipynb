{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle competition - Titanic\n",
    "\n",
    "#### Goal: Predict \"what sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "memory growth: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print('gpu', gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print('memory growth:' , tf.config.experimental.get_memory_growth(gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_titanic_data(filename):\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")\n",
    "df = pd.concat([train_data, test_data], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket  \n",
       "0       3    male      1       0.0         A/5 21171  \n",
       "1       1  female      1       1.0          PC 17599  \n",
       "2       3  female      0       1.0  STON/O2. 3101282  \n",
       "3       1  female      1       1.0            113803  \n",
       "4       3    male      0       0.0            373450  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A/5 21171', 'PC 17599', 'STON/O2. 3101282', '113803', '373450',\n",
       "       '330877', '17463', '349909', '347742', '237736', 'PP 9549',\n",
       "       '113783', 'A/5. 2151', '347082', '350406', '248706', '382652',\n",
       "       '244373', '345763', '2649', '239865', '248698', '330923', '113788',\n",
       "       '347077', '2631', '19950', '330959', '349216', 'PC 17601',\n",
       "       'PC 17569', '335677', 'C.A. 24579', 'PC 17604', '113789', '2677',\n",
       "       'A./5. 2152', '345764', '2651', '7546', '11668', '349253',\n",
       "       'SC/Paris 2123', '330958', 'S.C./A.4. 23567', '370371', '14311',\n",
       "       '2662', '349237', '3101295', 'A/4. 39886', 'PC 17572', '2926',\n",
       "       '113509', '19947', 'C.A. 31026', '2697', 'C.A. 34651', 'CA 2144',\n",
       "       '2669', '113572', '36973', '347088', 'PC 17605', '2661',\n",
       "       'C.A. 29395', 'S.P. 3464', '3101281', '315151', 'C.A. 33111',\n",
       "       'S.O.C. 14879', '2680', '1601', '348123', '349208', '374746',\n",
       "       '248738', '364516', '345767', '345779', '330932', '113059',\n",
       "       'SO/C 14885', '3101278', 'W./C. 6608', 'SOTON/OQ 392086', '343275',\n",
       "       '343276', '347466', 'W.E.P. 5734', 'C.A. 2315', '364500', '374910',\n",
       "       'PC 17754', 'PC 17759', '231919', '244367', '349245', '349215',\n",
       "       '35281', '7540', '3101276', '349207', '343120', '312991', '349249',\n",
       "       '371110', '110465', '2665', '324669', '4136', '2627',\n",
       "       'STON/O 2. 3101294', '370369', 'PC 17558', 'A4. 54510', '27267',\n",
       "       '370372', 'C 17369', '2668', '347061', '349241',\n",
       "       'SOTON/O.Q. 3101307', 'A/5. 3337', '228414', 'C.A. 29178',\n",
       "       'SC/PARIS 2133', '11752', '7534', 'PC 17593', '2678', '347081',\n",
       "       'STON/O2. 3101279', '365222', '231945', 'C.A. 33112', '350043',\n",
       "       '230080', '244310', 'S.O.P. 1166', '113776', 'A.5. 11206',\n",
       "       'A/5. 851', 'Fa 265302', 'PC 17597', '35851', 'SOTON/OQ 392090',\n",
       "       '315037', 'CA. 2343', '371362', 'C.A. 33595', '347068', '315093',\n",
       "       '363291', '113505', 'PC 17318', '111240', 'STON/O 2. 3101280',\n",
       "       '17764', '350404', '4133', 'PC 17595', '250653', 'LINE',\n",
       "       'SC/PARIS 2131', '230136', '315153', '113767', '370365', '111428',\n",
       "       '364849', '349247', '234604', '28424', '350046', 'PC 17610',\n",
       "       '368703', '4579', '370370', '248747', '345770', '3101264', '2628',\n",
       "       'A/5 3540', '347054', '2699', '367231', '112277',\n",
       "       'SOTON/O.Q. 3101311', 'F.C.C. 13528', 'A/5 21174', '250646',\n",
       "       '367229', '35273', 'STON/O2. 3101283', '243847', '11813',\n",
       "       'W/C 14208', 'SOTON/OQ 392089', '220367', '21440', '349234',\n",
       "       '19943', 'PP 4348', 'SW/PP 751', 'A/5 21173', '236171', '347067',\n",
       "       '237442', 'C.A. 29566', 'W./C. 6609', '26707', 'C.A. 31921',\n",
       "       '28665', 'SCO/W 1585', '367230', 'W./C. 14263',\n",
       "       'STON/O 2. 3101275', '2694', '19928', '347071', '250649', '11751',\n",
       "       '244252', '362316', '113514', 'A/5. 3336', '370129', '2650',\n",
       "       'PC 17585', '110152', 'PC 17755', '230433', '384461', '110413',\n",
       "       '112059', '382649', 'C.A. 17248', '347083', 'PC 17582', 'PC 17760',\n",
       "       '113798', '250644', 'PC 17596', '370375', '13502', '347073',\n",
       "       '239853', 'C.A. 2673', '336439', '347464', '345778', 'A/5. 10482',\n",
       "       '113056', '349239', '345774', '349206', '237798', '370373',\n",
       "       '19877', '11967', 'SC/Paris 2163', '349236', '349233', 'PC 17612',\n",
       "       '2693', '113781', '19988', '9234', '367226', '226593', 'A/5 2466',\n",
       "       '17421', 'PC 17758', 'P/PP 3381', 'PC 17485', '11767', 'PC 17608',\n",
       "       '250651', '349243', 'F.C.C. 13529', '347470', '29011', '36928',\n",
       "       '16966', 'A/5 21172', '349219', '234818', '345364', '28551',\n",
       "       '111361', '113043', 'PC 17611', '349225', '7598', '113784',\n",
       "       '248740', '244361', '229236', '248733', '31418', '386525',\n",
       "       'C.A. 37671', '315088', '7267', '113510', '2695', '2647', '345783',\n",
       "       '237671', '330931', '330980', 'SC/PARIS 2167', '2691',\n",
       "       'SOTON/O.Q. 3101310', 'C 7076', '110813', '2626', '14313',\n",
       "       'PC 17477', '11765', '3101267', '323951', 'C 7077', '113503',\n",
       "       '2648', '347069', 'PC 17757', '2653', 'STON/O 2. 3101293',\n",
       "       '349227', '27849', '367655', 'SC 1748', '113760', '350034',\n",
       "       '3101277', '350052', '350407', '28403', '244278', '240929',\n",
       "       'STON/O 2. 3101289', '341826', '4137', '315096', '28664', '347064',\n",
       "       '29106', '312992', '349222', '394140', 'STON/O 2. 3101269',\n",
       "       '343095', '28220', '250652', '28228', '345773', '349254',\n",
       "       'A/5. 13032', '315082', '347080', 'A/4. 34244', '2003', '250655',\n",
       "       '364851', 'SOTON/O.Q. 392078', '110564', '376564', 'SC/AH 3085',\n",
       "       'STON/O 2. 3101274', '13507', 'C.A. 18723', '345769', '347076',\n",
       "       '230434', '65306', '33638', '113794', '2666', '113786', '65303',\n",
       "       '113051', '17453', 'A/5 2817', '349240', '13509', '17464',\n",
       "       'F.C.C. 13531', '371060', '19952', '364506', '111320', '234360',\n",
       "       'A/S 2816', 'SOTON/O.Q. 3101306', '113792', '36209', '323592',\n",
       "       '315089', 'SC/AH Basle 541', '7553', '31027', '3460', '350060',\n",
       "       '3101298', '239854', 'A/5 3594', '4134', '11771', 'A.5. 18509',\n",
       "       '65304', 'SOTON/OQ 3101317', '113787', 'PC 17609', 'A/4 45380',\n",
       "       '36947', 'C.A. 6212', '350035', '315086', '364846', '330909',\n",
       "       '4135', '26360', '111427', 'C 4001', '382651', 'SOTON/OQ 3101316',\n",
       "       'PC 17473', 'PC 17603', '349209', '36967', 'C.A. 34260', '226875',\n",
       "       '349242', '12749', '349252', '2624', '2700', '367232',\n",
       "       'W./C. 14258', 'PC 17483', '3101296', '29104', '2641', '2690',\n",
       "       '315084', '113050', 'PC 17761', '364498', '13568', 'WE/P 5735',\n",
       "       '2908', '693', 'SC/PARIS 2146', '244358', '330979', '2620',\n",
       "       '347085', '113807', '11755', '345572', '372622', '349251',\n",
       "       '218629', 'SOTON/OQ 392082', 'SOTON/O.Q. 392087', 'A/4 48871',\n",
       "       '349205', '2686', '350417', 'S.W./PP 752', '11769', 'PC 17474',\n",
       "       '14312', 'A/4. 20589', '358585', '243880', '2689',\n",
       "       'STON/O 2. 3101286', '237789', '13049', '3411', '237565', '13567',\n",
       "       '14973', 'A./5. 3235', 'STON/O 2. 3101273', 'A/5 3902', '364848',\n",
       "       'SC/AH 29037', '248727', '2664', '349214', '113796', '364511',\n",
       "       '111426', '349910', '349246', '113804', 'SOTON/O.Q. 3101305',\n",
       "       '370377', '364512', '220845', '31028', '2659', '11753', '350029',\n",
       "       '54636', '36963', '219533', '349224', '334912', '27042', '347743',\n",
       "       '13214', '112052', '237668', 'STON/O 2. 3101292', '350050',\n",
       "       '349231', '13213', 'S.O./P.P. 751', 'CA. 2314', '349221', '8475',\n",
       "       '330919', '365226', '349223', '29751', '2623', '5727', '349210',\n",
       "       'STON/O 2. 3101285', '234686', '312993', 'A/5 3536', '19996',\n",
       "       '29750', 'F.C. 12750', 'C.A. 24580', '244270', '239856', '349912',\n",
       "       '342826', '4138', '330935', '6563', '349228', '350036', '24160',\n",
       "       '17474', '349256', '2672', '113800', '248731', '363592', '35852',\n",
       "       '348121', 'PC 17475', '36864', '350025', '223596', 'PC 17476',\n",
       "       'PC 17482', '113028', '7545', '250647', '348124', '34218', '36568',\n",
       "       '347062', '350048', '12233', '250643', '113806', '315094', '36866',\n",
       "       '236853', 'STON/O2. 3101271', '239855', '28425', '233639',\n",
       "       '349201', '349218', '16988', '376566', 'STON/O 2. 3101288',\n",
       "       '250648', '113773', '335097', '29103', '392096', '345780',\n",
       "       '349204', '350042', '29108', '363294', 'SOTON/O2 3101272', '2663',\n",
       "       '347074', '112379', '364850', '8471', '345781', '350047',\n",
       "       'S.O./P.P. 3', '2674', '29105', '347078', '383121', '36865',\n",
       "       '2687', '113501', 'W./C. 6607', 'SOTON/O.Q. 3101312', '374887',\n",
       "       '3101265', '12460', 'PC 17600', '349203', '28213', '17465',\n",
       "       '349244', '2685', '2625', '347089', '347063', '112050', '347087',\n",
       "       '248723', '3474', '28206', '364499', '112058', 'STON/O2. 3101290',\n",
       "       'S.C./PARIS 2079', 'C 7075', '315098', '19972', '368323', '367228',\n",
       "       '2671', '347468', '2223', 'PC 17756', '315097', '392092', '11774',\n",
       "       'SOTON/O2 3101287', '2683', '315090', 'C.A. 5547', '349213',\n",
       "       '347060', 'PC 17592', '392091', '113055', '2629', '350026',\n",
       "       '28134', '17466', '233866', '236852', 'SC/PARIS 2149', 'PC 17590',\n",
       "       '345777', '349248', '695', '345765', '2667', '349212', '349217',\n",
       "       '349257', '7552', 'C.A./SOTON 34068', 'SOTON/OQ 392076', '211536',\n",
       "       '112053', '111369', '370376', '330911', '363272', '240276',\n",
       "       '315154', '7538', '330972', '2657', '349220', '694', '21228',\n",
       "       '24065', '233734', '2692', 'STON/O2. 3101270', '2696', 'C 17368',\n",
       "       'PC 17598', '2698', '113054', 'C.A. 31029', '13236', '2682',\n",
       "       '342712', '315087', '345768', '113778', 'SOTON/O.Q. 3101263',\n",
       "       '237249', 'STON/O 2. 3101291', 'PC 17594', '370374', '13695',\n",
       "       'SC/PARIS 2168', 'SC/A.3 2861', '349230', '348122', '349232',\n",
       "       '237216', '347090', '334914', 'F.C.C. 13534', '330963', '2543',\n",
       "       '382653', '349211', '3101297', 'PC 17562', '359306', '11770',\n",
       "       '248744', '368702', '19924', '349238', '240261', '2660', '330844',\n",
       "       'A/4 31416', '364856', '347072', '345498', '376563', '13905',\n",
       "       '350033', 'STON/O 2. 3101268', '347471', 'A./5. 3338', '11778',\n",
       "       '365235', '347070', '330920', '383162', '3410', '248734', '237734',\n",
       "       '330968', 'PC 17531', '329944', '2681', '13050', '367227',\n",
       "       '392095', '368783', '350045', '211535', '342441',\n",
       "       'STON/OQ. 369943', '113780', '2621', '349226', '350409', '2656',\n",
       "       '248659', 'SOTON/OQ 392083', '17475', 'SC/A4 23568', '113791',\n",
       "       '349255', '3701', '350405', 'S.O./P.P. 752', '347469', '110489',\n",
       "       'SOTON/O.Q. 3101315', '335432', '220844', '343271', '237393',\n",
       "       'PC 17591', '17770', '7548', 'S.O./P.P. 251', '2670', '2673',\n",
       "       '233478', '7935', '239059', 'S.O./P.P. 2', 'A/4 48873', '28221',\n",
       "       '111163', '235509', '347465', '347066', 'C.A. 31030', '65305',\n",
       "       'C.A. 34050', 'F.C. 12998', '9232', '28034', 'PC 17613', '349250',\n",
       "       'SOTON/O.Q. 3101308', '347091', '113038', '330924', '32302',\n",
       "       'SC/PARIS 2148', '342684', 'W./C. 14266', '350053', 'PC 17606',\n",
       "       '350054', '370368', '242963', '113795', '3101266', '330971',\n",
       "       '350416', '2679', '250650', '112377', '3470', 'SOTON/O2 3101284',\n",
       "       '13508', '7266', '345775', 'C.A. 42795', 'AQ/4 3130', '363611',\n",
       "       '28404', '345501', '350410', 'C.A. 34644', '349235', '112051',\n",
       "       'C.A. 49867', 'A. 2. 39186', '315095', '368573', '2676',\n",
       "       'SC 14888', 'CA 31352', 'W./C. 14260', '315085', '364859',\n",
       "       'A/5 21175', 'SOTON/O.Q. 3101314', '2655', 'A/5 1478', 'PC 17607',\n",
       "       '382650', '2652', '345771', '349202', '113801', '347467', '347079',\n",
       "       '237735', '315092', '383123', '112901', '315091', '2658',\n",
       "       'LP 1588', '368364', 'AQ/3. 30631', '28004', '350408', '347075',\n",
       "       '2654', '244368', '113790', 'SOTON/O.Q. 3101309', '236854',\n",
       "       'PC 17580', '2684', '349229', '110469', '244360', '2675', '2622',\n",
       "       'C.A. 15185', '350403', '348125', '237670', '2688', '248726',\n",
       "       'F.C.C. 13540', '113044', '1222', '368402', '315083', '112378',\n",
       "       'SC/PARIS 2147', '28133', '248746', '315152', '29107', '680',\n",
       "       '366713', '330910', 'SC/PARIS 2159', '349911', '244346', '364858',\n",
       "       'C.A. 30769', '371109', '347065', '21332', '17765',\n",
       "       'SC/PARIS 2166', '28666', '334915', '365237', '347086',\n",
       "       'A.5. 3236', 'SOTON/O.Q. 3101262', '359309'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ticket'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns we don't want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare  Parch  PassengerId  Pclass     Sex  SibSp  Survived\n",
       "0  22.0        S   7.2500      0            1       3    male      1       0.0\n",
       "1  38.0        C  71.2833      0            2       1  female      1       1.0\n",
       "2  26.0        S   7.9250      0            3       3  female      0       1.0\n",
       "3  35.0        S  53.1000      0            4       1  female      1       1.0\n",
       "4  35.0        S   8.0500      0            5       3    male      0       0.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.drop(columns=[\"Name\", \"Cabin\", \"Ticket\"], axis=1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "result = OneHotEncoder().fit_transform(df['Sex'].values.reshape(-1, 1)).toarray()\n",
    "df_new[['Female', 'Male']] = pd.DataFrame(result, index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare  Parch  PassengerId  Pclass     Sex  SibSp  \\\n",
       "0  22.0        S   7.2500      0            1       3    male      1   \n",
       "1  38.0        C  71.2833      0            2       1  female      1   \n",
       "2  26.0        S   7.9250      0            3       3  female      0   \n",
       "3  35.0        S  53.1000      0            4       1  female      1   \n",
       "4  35.0        S   8.0500      0            5       3    male      0   \n",
       "\n",
       "   Survived  Female  Male  \n",
       "0       0.0     0.0   1.0  \n",
       "1       1.0     1.0   0.0  \n",
       "2       1.0     1.0   0.0  \n",
       "3       1.0     1.0   0.0  \n",
       "4       0.0     0.0   1.0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(columns=[\"Embarked\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Parch  PassengerId  Pclass  SibSp  Survived  Female  Male\n",
       "0  22.0   7.2500      0            1       3      1       0.0     0.0   1.0\n",
       "1  38.0  71.2833      0            2       1      1       1.0     1.0   0.0\n",
       "2  26.0   7.9250      0            3       3      0       1.0     1.0   0.0\n",
       "3  35.0  53.1000      0            4       1      1       1.0     1.0   0.0\n",
       "4  35.0   8.0500      0            5       3      0       0.0     0.0   1.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"Survived\",\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Age          1309 non-null   float64\n",
      " 1   Fare         1308 non-null   float64\n",
      " 2   Parch        1309 non-null   int64  \n",
      " 3   PassengerId  1309 non-null   int64  \n",
      " 4   Pclass       1309 non-null   int64  \n",
      " 5   SibSp        1309 non-null   int64  \n",
      " 6   Survived     891 non-null    float64\n",
      " 7   Female       1309 non-null   float64\n",
      " 8   Male         1309 non-null   float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 102.3 KB\n"
     ]
    }
   ],
   "source": [
    "median = df_new[\"Age\"].median()\n",
    "df_new[\"Age\"].fillna(median, inplace=True)\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "df_new[\"Fare\"] = mm_scaler.fit_transform(df_new[\"Fare\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age      Fare  Parch  PassengerId  Pclass  SibSp  Survived  Female  Male\n",
       "0  22.0  0.014151      0            1       3      1       0.0     0.0   1.0\n",
       "1  38.0  0.139136      0            2       1      1       1.0     1.0   0.0\n",
       "2  26.0  0.015469      0            3       3      0       1.0     1.0   0.0\n",
       "3  35.0  0.103644      0            4       1      1       1.0     1.0   0.0\n",
       "4  35.0  0.015713      0            5       3      0       0.0     0.0   1.0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_new[pd.notnull(df['Survived'])]\n",
    "test = df_new[pd.isnull(df['Survived'])]\n",
    "test = test.drop(columns=['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age      Fare  Parch  PassengerId  Pclass  SibSp  Survived  Female  Male\n",
       "0  22.0  0.014151      0            1       3      1       0.0     0.0   1.0\n",
       "1  38.0  0.139136      0            2       1      1       1.0     1.0   0.0\n",
       "2  26.0  0.015469      0            3       3      0       1.0     1.0   0.0\n",
       "3  35.0  0.103644      0            4       1      1       1.0     1.0   0.0\n",
       "4  35.0  0.015713      0            5       3      0       0.0     0.0   1.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age      Fare  Parch  PassengerId  Pclass  SibSp  Female  Male\n",
       "0  34.5  0.015282      0          892       3      0     0.0   1.0\n",
       "1  47.0  0.013663      0          893       3      1     1.0   0.0\n",
       "2  62.0  0.018909      0          894       2      0     0.0   1.0\n",
       "3  27.0  0.016908      0          895       3      0     0.0   1.0\n",
       "4  22.0  0.023984      1          896       3      1     1.0   0.0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target column\n",
    "X = train.drop(\"Survived\", axis = 1)\n",
    "# Store the target column in y\n",
    "y = train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age      Fare  Parch  PassengerId  Pclass  SibSp  Female  Male\n",
       "0  22.0  0.014151      0            1       3      1     0.0   1.0\n",
       "1  38.0  0.139136      0            2       1      1     1.0   0.0\n",
       "2  26.0  0.015469      0            3       3      0     1.0   0.0\n",
       "3  35.0  0.103644      0            4       1      1     1.0   0.0\n",
       "4  35.0  0.015713      0            5       3      0     0.0   1.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(8, activation=\"relu\", input_shape=(8,)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(50, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(50, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.7725 - val_loss: 0.5410 - val_accuracy: 0.7877\n",
      "Epoch 2/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7893 - val_loss: 0.4397 - val_accuracy: 0.8380\n",
      "Epoch 3/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7739 - val_loss: 0.4680 - val_accuracy: 0.8268\n",
      "Epoch 4/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7739 - val_loss: 0.5446 - val_accuracy: 0.7933\n",
      "Epoch 5/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.7654 - val_loss: 0.4707 - val_accuracy: 0.8268\n",
      "Epoch 6/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7921 - val_loss: 0.4690 - val_accuracy: 0.8212\n",
      "Epoch 7/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7949 - val_loss: 0.5214 - val_accuracy: 0.8045\n",
      "Epoch 8/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7725 - val_loss: 0.4937 - val_accuracy: 0.8156\n",
      "Epoch 9/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7823 - val_loss: 0.4509 - val_accuracy: 0.8156\n",
      "Epoch 10/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7851 - val_loss: 0.4860 - val_accuracy: 0.8212\n",
      "Epoch 11/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7753 - val_loss: 0.5909 - val_accuracy: 0.6425\n",
      "Epoch 12/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7683 - val_loss: 0.4920 - val_accuracy: 0.8156\n",
      "Epoch 13/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7669 - val_loss: 0.4613 - val_accuracy: 0.8324\n",
      "Epoch 14/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7795 - val_loss: 0.5524 - val_accuracy: 0.7877\n",
      "Epoch 15/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7767 - val_loss: 0.4872 - val_accuracy: 0.8268\n",
      "Epoch 16/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7877\n",
      "Epoch 17/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7809 - val_loss: 0.4881 - val_accuracy: 0.8101\n",
      "Epoch 18/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7879 - val_loss: 0.4690 - val_accuracy: 0.8101\n",
      "Epoch 19/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7767 - val_loss: 0.4753 - val_accuracy: 0.8212\n",
      "Epoch 20/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7851 - val_loss: 0.4495 - val_accuracy: 0.8268\n",
      "Epoch 21/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7753 - val_loss: 0.4970 - val_accuracy: 0.8212\n",
      "Epoch 22/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7725 - val_loss: 0.4716 - val_accuracy: 0.8268\n",
      "Epoch 23/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7767 - val_loss: 0.5114 - val_accuracy: 0.8156\n",
      "Epoch 24/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7865 - val_loss: 0.4818 - val_accuracy: 0.8212\n",
      "Epoch 25/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.7739 - val_loss: 0.5467 - val_accuracy: 0.7654\n",
      "Epoch 26/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7711 - val_loss: 0.4728 - val_accuracy: 0.8101\n",
      "Epoch 27/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7781 - val_loss: 0.4572 - val_accuracy: 0.8101\n",
      "Epoch 28/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7711 - val_loss: 0.4446 - val_accuracy: 0.8324\n",
      "Epoch 29/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7851 - val_loss: 0.4967 - val_accuracy: 0.8156\n",
      "Epoch 30/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7739 - val_loss: 0.5017 - val_accuracy: 0.8156\n",
      "Epoch 31/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7809 - val_loss: 0.5005 - val_accuracy: 0.8156\n",
      "Epoch 32/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7809 - val_loss: 0.4750 - val_accuracy: 0.8268\n",
      "Epoch 33/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7809 - val_loss: 0.4926 - val_accuracy: 0.8156\n",
      "Epoch 34/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7669 - val_loss: 0.4711 - val_accuracy: 0.8212\n",
      "Epoch 35/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7781 - val_loss: 0.5338 - val_accuracy: 0.8045\n",
      "Epoch 36/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7851 - val_loss: 0.4542 - val_accuracy: 0.8268\n",
      "Epoch 37/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7837 - val_loss: 0.5212 - val_accuracy: 0.8212\n",
      "Epoch 38/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7865 - val_loss: 0.4537 - val_accuracy: 0.8156\n",
      "Epoch 39/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7879 - val_loss: 0.5356 - val_accuracy: 0.6983\n",
      "Epoch 40/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7935 - val_loss: 0.4754 - val_accuracy: 0.8212\n",
      "Epoch 41/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7809 - val_loss: 0.4583 - val_accuracy: 0.8212\n",
      "Epoch 42/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.7697 - val_loss: 0.4777 - val_accuracy: 0.8212\n",
      "Epoch 43/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7781 - val_loss: 0.5549 - val_accuracy: 0.7877\n",
      "Epoch 44/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7683 - val_loss: 0.4550 - val_accuracy: 0.8380\n",
      "Epoch 45/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7935 - val_loss: 0.4550 - val_accuracy: 0.8380\n",
      "Epoch 46/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7739 - val_loss: 0.5095 - val_accuracy: 0.7877\n",
      "Epoch 47/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7739 - val_loss: 0.4563 - val_accuracy: 0.8212\n",
      "Epoch 48/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7654 - val_loss: 0.4556 - val_accuracy: 0.8268\n",
      "Epoch 49/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7739 - val_loss: 0.4766 - val_accuracy: 0.8212\n",
      "Epoch 50/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7739 - val_loss: 0.4408 - val_accuracy: 0.8268\n",
      "Epoch 51/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7809 - val_loss: 0.4808 - val_accuracy: 0.7877\n",
      "Epoch 52/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8006 - val_loss: 0.5163 - val_accuracy: 0.8156\n",
      "Epoch 53/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7767 - val_loss: 0.4901 - val_accuracy: 0.8156\n",
      "Epoch 54/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7809 - val_loss: 0.4855 - val_accuracy: 0.8212\n",
      "Epoch 55/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7851 - val_loss: 0.5500 - val_accuracy: 0.7765\n",
      "Epoch 56/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7598 - val_loss: 0.5092 - val_accuracy: 0.8045\n",
      "Epoch 57/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7809 - val_loss: 0.4531 - val_accuracy: 0.8324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7879 - val_loss: 0.5929 - val_accuracy: 0.6648\n",
      "Epoch 59/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7865 - val_loss: 0.4719 - val_accuracy: 0.8101\n",
      "Epoch 60/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7795 - val_loss: 0.4485 - val_accuracy: 0.8436\n",
      "Epoch 61/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7879 - val_loss: 0.4680 - val_accuracy: 0.8212\n",
      "Epoch 62/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7935 - val_loss: 0.4741 - val_accuracy: 0.8324\n",
      "Epoch 63/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7865 - val_loss: 0.5383 - val_accuracy: 0.7877\n",
      "Epoch 64/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7907 - val_loss: 0.4527 - val_accuracy: 0.8268\n",
      "Epoch 65/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7795 - val_loss: 0.4520 - val_accuracy: 0.8380\n",
      "Epoch 66/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7739 - val_loss: 0.4716 - val_accuracy: 0.8324\n",
      "Epoch 67/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7809 - val_loss: 0.4601 - val_accuracy: 0.8324\n",
      "Epoch 68/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7851 - val_loss: 0.5238 - val_accuracy: 0.7821\n",
      "Epoch 69/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7669 - val_loss: 0.5342 - val_accuracy: 0.7039\n",
      "Epoch 70/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7654 - val_loss: 0.4609 - val_accuracy: 0.8324\n",
      "Epoch 71/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7823 - val_loss: 0.4688 - val_accuracy: 0.8324\n",
      "Epoch 72/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7781 - val_loss: 0.5358 - val_accuracy: 0.7877\n",
      "Epoch 73/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7711 - val_loss: 0.4896 - val_accuracy: 0.8156\n",
      "Epoch 74/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7767 - val_loss: 0.4917 - val_accuracy: 0.8268\n",
      "Epoch 75/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7893 - val_loss: 0.4659 - val_accuracy: 0.7989\n",
      "Epoch 76/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.7809 - val_loss: 0.5270 - val_accuracy: 0.7989\n",
      "Epoch 77/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7739 - val_loss: 0.4540 - val_accuracy: 0.8268\n",
      "Epoch 78/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7725 - val_loss: 0.5034 - val_accuracy: 0.8212\n",
      "Epoch 79/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7697 - val_loss: 0.4719 - val_accuracy: 0.8212\n",
      "Epoch 80/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7851 - val_loss: 0.4976 - val_accuracy: 0.8156\n",
      "Epoch 81/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7809 - val_loss: 0.4795 - val_accuracy: 0.7821\n",
      "Epoch 82/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7865 - val_loss: 0.4659 - val_accuracy: 0.8380\n",
      "Epoch 83/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7978 - val_loss: 0.4610 - val_accuracy: 0.8324\n",
      "Epoch 84/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7781 - val_loss: 0.5351 - val_accuracy: 0.8156\n",
      "Epoch 85/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5242 - accuracy: 0.7767 - val_loss: 0.4438 - val_accuracy: 0.8324\n",
      "Epoch 86/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.8324\n",
      "Epoch 87/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7753 - val_loss: 0.4687 - val_accuracy: 0.8268\n",
      "Epoch 88/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7767 - val_loss: 0.4636 - val_accuracy: 0.8324\n",
      "Epoch 89/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7781 - val_loss: 0.4936 - val_accuracy: 0.8045\n",
      "Epoch 90/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7795 - val_loss: 0.4463 - val_accuracy: 0.8324\n",
      "Epoch 91/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7823 - val_loss: 0.5012 - val_accuracy: 0.7765\n",
      "Epoch 92/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7921 - val_loss: 0.5581 - val_accuracy: 0.7877\n",
      "Epoch 93/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7823 - val_loss: 0.4977 - val_accuracy: 0.8212\n",
      "Epoch 94/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7795 - val_loss: 0.4544 - val_accuracy: 0.8212\n",
      "Epoch 95/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7921 - val_loss: 0.4657 - val_accuracy: 0.8212\n",
      "Epoch 96/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.7949 - val_loss: 0.5119 - val_accuracy: 0.7989\n",
      "Epoch 97/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7837 - val_loss: 0.4587 - val_accuracy: 0.8156\n",
      "Epoch 98/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7739 - val_loss: 0.4584 - val_accuracy: 0.8268\n",
      "Epoch 99/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7725 - val_loss: 0.4517 - val_accuracy: 0.8268\n",
      "Epoch 100/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7711 - val_loss: 0.4432 - val_accuracy: 0.8380\n",
      "Epoch 101/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.8156\n",
      "Epoch 102/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7809 - val_loss: 0.4754 - val_accuracy: 0.8156\n",
      "Epoch 103/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7865 - val_loss: 0.4339 - val_accuracy: 0.8324\n",
      "Epoch 104/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7767 - val_loss: 0.4579 - val_accuracy: 0.8324\n",
      "Epoch 105/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7935 - val_loss: 0.4827 - val_accuracy: 0.8156\n",
      "Epoch 106/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7767 - val_loss: 0.4659 - val_accuracy: 0.8380\n",
      "Epoch 107/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7739 - val_loss: 0.5326 - val_accuracy: 0.7821\n",
      "Epoch 108/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7837 - val_loss: 0.4670 - val_accuracy: 0.8324\n",
      "Epoch 109/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7683 - val_loss: 0.4987 - val_accuracy: 0.8268\n",
      "Epoch 110/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7893 - val_loss: 0.5129 - val_accuracy: 0.7933\n",
      "Epoch 111/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7837 - val_loss: 0.4807 - val_accuracy: 0.7933\n",
      "Epoch 112/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7809 - val_loss: 0.4768 - val_accuracy: 0.8324\n",
      "Epoch 113/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.7612 - val_loss: 0.5165 - val_accuracy: 0.8045\n",
      "Epoch 114/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7767 - val_loss: 0.5003 - val_accuracy: 0.8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7683 - val_loss: 0.6592 - val_accuracy: 0.6536\n",
      "Epoch 116/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7823 - val_loss: 0.4549 - val_accuracy: 0.8268\n",
      "Epoch 117/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.7753 - val_loss: 0.4962 - val_accuracy: 0.7933\n",
      "Epoch 118/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7669 - val_loss: 0.4385 - val_accuracy: 0.8324\n",
      "Epoch 119/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7879 - val_loss: 0.5124 - val_accuracy: 0.8268\n",
      "Epoch 120/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7795 - val_loss: 0.4695 - val_accuracy: 0.8212\n",
      "Epoch 121/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7767 - val_loss: 0.4739 - val_accuracy: 0.8212\n",
      "Epoch 122/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7823 - val_loss: 0.4715 - val_accuracy: 0.8268\n",
      "Epoch 123/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7640 - val_loss: 0.4737 - val_accuracy: 0.7877\n",
      "Epoch 124/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7725 - val_loss: 0.4979 - val_accuracy: 0.8268\n",
      "Epoch 125/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7781 - val_loss: 0.4932 - val_accuracy: 0.8156\n",
      "Epoch 126/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7711 - val_loss: 0.4679 - val_accuracy: 0.8324\n",
      "Epoch 127/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7879 - val_loss: 0.4785 - val_accuracy: 0.8156\n",
      "Epoch 128/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7851 - val_loss: 0.4723 - val_accuracy: 0.8156\n",
      "Epoch 129/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.8006 - val_loss: 0.4712 - val_accuracy: 0.8156\n",
      "Epoch 130/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7781 - val_loss: 0.4880 - val_accuracy: 0.8380\n",
      "Epoch 131/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7781 - val_loss: 0.4731 - val_accuracy: 0.8324\n",
      "Epoch 132/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7809 - val_loss: 0.5374 - val_accuracy: 0.7877\n",
      "Epoch 133/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7921 - val_loss: 0.5001 - val_accuracy: 0.8268\n",
      "Epoch 134/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7823 - val_loss: 0.4469 - val_accuracy: 0.8268\n",
      "Epoch 135/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7865 - val_loss: 0.4807 - val_accuracy: 0.8156\n",
      "Epoch 136/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7851 - val_loss: 0.4574 - val_accuracy: 0.8380\n",
      "Epoch 137/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7767 - val_loss: 0.5101 - val_accuracy: 0.8156\n",
      "Epoch 138/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7781 - val_loss: 0.4652 - val_accuracy: 0.8324\n",
      "Epoch 139/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.7907 - val_loss: 0.5293 - val_accuracy: 0.8156\n",
      "Epoch 140/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7781 - val_loss: 0.4880 - val_accuracy: 0.8324\n",
      "Epoch 141/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7767 - val_loss: 0.4546 - val_accuracy: 0.8101\n",
      "Epoch 142/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7753 - val_loss: 0.5289 - val_accuracy: 0.7989\n",
      "Epoch 143/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7767 - val_loss: 0.4743 - val_accuracy: 0.8212\n",
      "Epoch 144/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7753 - val_loss: 0.5207 - val_accuracy: 0.7821\n",
      "Epoch 145/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.7725 - val_loss: 0.4537 - val_accuracy: 0.8324\n",
      "Epoch 146/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7837 - val_loss: 0.5462 - val_accuracy: 0.7989\n",
      "Epoch 147/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7809 - val_loss: 0.4765 - val_accuracy: 0.8156\n",
      "Epoch 148/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7753 - val_loss: 0.4826 - val_accuracy: 0.8156\n",
      "Epoch 149/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7907 - val_loss: 0.5766 - val_accuracy: 0.6760\n",
      "Epoch 150/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.7809 - val_loss: 0.5117 - val_accuracy: 0.8156\n",
      "Epoch 151/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7767 - val_loss: 0.4961 - val_accuracy: 0.8156\n",
      "Epoch 152/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7711 - val_loss: 0.4461 - val_accuracy: 0.8268\n",
      "Epoch 153/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7893 - val_loss: 0.5146 - val_accuracy: 0.7933\n",
      "Epoch 154/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5257 - accuracy: 0.7753 - val_loss: 0.4766 - val_accuracy: 0.8156\n",
      "Epoch 155/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7809 - val_loss: 0.4379 - val_accuracy: 0.8045\n",
      "Epoch 156/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7949 - val_loss: 0.4795 - val_accuracy: 0.8324\n",
      "Epoch 157/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.7725 - val_loss: 0.4822 - val_accuracy: 0.8268\n",
      "Epoch 158/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7781 - val_loss: 0.5712 - val_accuracy: 0.7821\n",
      "Epoch 159/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7781 - val_loss: 0.4580 - val_accuracy: 0.8380\n",
      "Epoch 160/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7753 - val_loss: 0.4594 - val_accuracy: 0.8324\n",
      "Epoch 161/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7809 - val_loss: 0.4927 - val_accuracy: 0.8156\n",
      "Epoch 162/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7809 - val_loss: 0.4753 - val_accuracy: 0.8268\n",
      "Epoch 163/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7851 - val_loss: 0.4402 - val_accuracy: 0.8324\n",
      "Epoch 164/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7823 - val_loss: 0.4898 - val_accuracy: 0.8268\n",
      "Epoch 165/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7865 - val_loss: 0.4831 - val_accuracy: 0.8212\n",
      "Epoch 166/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7725 - val_loss: 0.5864 - val_accuracy: 0.7765\n",
      "Epoch 167/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7739 - val_loss: 0.4454 - val_accuracy: 0.8324\n",
      "Epoch 168/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7669 - val_loss: 0.4580 - val_accuracy: 0.8324\n",
      "Epoch 169/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7795 - val_loss: 0.4981 - val_accuracy: 0.8268\n",
      "Epoch 170/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7767 - val_loss: 0.4407 - val_accuracy: 0.8324\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7865 - val_loss: 0.5772 - val_accuracy: 0.7709\n",
      "Epoch 172/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7795 - val_loss: 0.4746 - val_accuracy: 0.8324\n",
      "Epoch 173/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7809 - val_loss: 0.5060 - val_accuracy: 0.8045\n",
      "Epoch 174/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.7654 - val_loss: 0.4665 - val_accuracy: 0.8324\n",
      "Epoch 175/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7781 - val_loss: 0.4930 - val_accuracy: 0.8380\n",
      "Epoch 176/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7851 - val_loss: 0.4781 - val_accuracy: 0.8268\n",
      "Epoch 177/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7907 - val_loss: 0.5110 - val_accuracy: 0.8156\n",
      "Epoch 178/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7851 - val_loss: 0.4523 - val_accuracy: 0.8268\n",
      "Epoch 179/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7823 - val_loss: 0.5109 - val_accuracy: 0.7263\n",
      "Epoch 180/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7963 - val_loss: 0.4690 - val_accuracy: 0.8324\n",
      "Epoch 181/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7626 - val_loss: 0.4721 - val_accuracy: 0.8324\n",
      "Epoch 182/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7795 - val_loss: 0.4690 - val_accuracy: 0.8268\n",
      "Epoch 183/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7865 - val_loss: 0.4653 - val_accuracy: 0.8268\n",
      "Epoch 184/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7949 - val_loss: 0.4946 - val_accuracy: 0.8268\n",
      "Epoch 185/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7851 - val_loss: 0.4479 - val_accuracy: 0.8324\n",
      "Epoch 186/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7697 - val_loss: 0.5011 - val_accuracy: 0.7263\n",
      "Epoch 187/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.7683 - val_loss: 0.4509 - val_accuracy: 0.8268\n",
      "Epoch 188/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7851 - val_loss: 0.4822 - val_accuracy: 0.7933\n",
      "Epoch 189/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7809 - val_loss: 0.4778 - val_accuracy: 0.8324\n",
      "Epoch 190/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7865 - val_loss: 0.4900 - val_accuracy: 0.8156\n",
      "Epoch 191/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7921 - val_loss: 0.4422 - val_accuracy: 0.8324\n",
      "Epoch 192/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7683 - val_loss: 0.4685 - val_accuracy: 0.8212\n",
      "Epoch 193/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7949 - val_loss: 0.5122 - val_accuracy: 0.7989\n",
      "Epoch 194/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7978 - val_loss: 0.4151 - val_accuracy: 0.8380\n",
      "Epoch 195/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7851 - val_loss: 0.4642 - val_accuracy: 0.8101\n",
      "Epoch 196/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.7809 - val_loss: 0.5275 - val_accuracy: 0.7933\n",
      "Epoch 197/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7851 - val_loss: 0.4384 - val_accuracy: 0.8268\n",
      "Epoch 198/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7781 - val_loss: 0.5038 - val_accuracy: 0.7933\n",
      "Epoch 199/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7921 - val_loss: 0.4341 - val_accuracy: 0.8268\n",
      "Epoch 200/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7739 - val_loss: 0.4680 - val_accuracy: 0.8268\n",
      "Epoch 201/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7893 - val_loss: 0.4861 - val_accuracy: 0.8268\n",
      "Epoch 202/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7865 - val_loss: 0.4829 - val_accuracy: 0.7989\n",
      "Epoch 203/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7767 - val_loss: 0.4751 - val_accuracy: 0.8268\n",
      "Epoch 204/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7921 - val_loss: 0.4460 - val_accuracy: 0.8268\n",
      "Epoch 205/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7865 - val_loss: 0.4377 - val_accuracy: 0.8324\n",
      "Epoch 206/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7879 - val_loss: 0.4641 - val_accuracy: 0.8324\n",
      "Epoch 207/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7767 - val_loss: 0.4688 - val_accuracy: 0.8156\n",
      "Epoch 208/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7851 - val_loss: 0.4752 - val_accuracy: 0.8156\n",
      "Epoch 209/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7795 - val_loss: 0.5313 - val_accuracy: 0.7877\n",
      "Epoch 210/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7837 - val_loss: 0.4556 - val_accuracy: 0.8324\n",
      "Epoch 211/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7893 - val_loss: 0.4828 - val_accuracy: 0.8324\n",
      "Epoch 212/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.7739 - val_loss: 0.5348 - val_accuracy: 0.7877\n",
      "Epoch 213/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7809 - val_loss: 0.4604 - val_accuracy: 0.8045\n",
      "Epoch 214/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7725 - val_loss: 0.4433 - val_accuracy: 0.8324\n",
      "Epoch 215/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7921 - val_loss: 0.4505 - val_accuracy: 0.8324\n",
      "Epoch 216/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7837 - val_loss: 0.4974 - val_accuracy: 0.8268\n",
      "Epoch 217/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7739 - val_loss: 0.4884 - val_accuracy: 0.7989\n",
      "Epoch 218/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7795 - val_loss: 0.4971 - val_accuracy: 0.8156\n",
      "Epoch 219/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7795 - val_loss: 0.4601 - val_accuracy: 0.8380\n",
      "Epoch 220/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7851 - val_loss: 0.4870 - val_accuracy: 0.8156\n",
      "Epoch 221/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7809 - val_loss: 0.5241 - val_accuracy: 0.7877\n",
      "Epoch 222/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7809 - val_loss: 0.5729 - val_accuracy: 0.7709\n",
      "Epoch 223/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7893 - val_loss: 0.4596 - val_accuracy: 0.8324\n",
      "Epoch 224/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7781 - val_loss: 0.4816 - val_accuracy: 0.8268\n",
      "Epoch 225/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7753 - val_loss: 0.4618 - val_accuracy: 0.8324\n",
      "Epoch 226/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7893 - val_loss: 0.4914 - val_accuracy: 0.8156\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7725 - val_loss: 0.5410 - val_accuracy: 0.7933\n",
      "Epoch 228/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7963 - val_loss: 0.4572 - val_accuracy: 0.8101\n",
      "Epoch 229/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8034 - val_loss: 0.4430 - val_accuracy: 0.8045\n",
      "Epoch 230/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7837 - val_loss: 0.4977 - val_accuracy: 0.8212\n",
      "Epoch 231/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7837 - val_loss: 0.4754 - val_accuracy: 0.7877\n",
      "Epoch 232/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7697 - val_loss: 0.4684 - val_accuracy: 0.8324\n",
      "Epoch 233/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7921 - val_loss: 0.4637 - val_accuracy: 0.8324\n",
      "Epoch 234/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7654 - val_loss: 0.4940 - val_accuracy: 0.8268\n",
      "Epoch 235/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7837 - val_loss: 0.4468 - val_accuracy: 0.8324\n",
      "Epoch 236/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7809 - val_loss: 0.5458 - val_accuracy: 0.7877\n",
      "Epoch 237/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7935 - val_loss: 0.4815 - val_accuracy: 0.8212\n",
      "Epoch 238/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.7725 - val_loss: 0.4565 - val_accuracy: 0.8324\n",
      "Epoch 239/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7711 - val_loss: 0.4865 - val_accuracy: 0.8212\n",
      "Epoch 240/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7893 - val_loss: 0.4401 - val_accuracy: 0.8380\n",
      "Epoch 241/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7711 - val_loss: 0.4801 - val_accuracy: 0.8268\n",
      "Epoch 242/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7753 - val_loss: 0.5150 - val_accuracy: 0.7933\n",
      "Epoch 243/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7739 - val_loss: 0.5520 - val_accuracy: 0.7709\n",
      "Epoch 244/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7781 - val_loss: 0.4693 - val_accuracy: 0.7989\n",
      "Epoch 245/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7795 - val_loss: 0.4406 - val_accuracy: 0.8324\n",
      "Epoch 246/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7711 - val_loss: 0.4794 - val_accuracy: 0.8156\n",
      "Epoch 247/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7739 - val_loss: 0.4525 - val_accuracy: 0.8324\n",
      "Epoch 248/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7837 - val_loss: 0.4299 - val_accuracy: 0.8380\n",
      "Epoch 249/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7837 - val_loss: 0.4642 - val_accuracy: 0.8212\n",
      "Epoch 250/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7753 - val_loss: 0.4729 - val_accuracy: 0.8156\n",
      "Epoch 251/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7767 - val_loss: 0.4973 - val_accuracy: 0.7989\n",
      "Epoch 252/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7697 - val_loss: 0.5204 - val_accuracy: 0.7933\n",
      "Epoch 253/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7795 - val_loss: 0.4483 - val_accuracy: 0.8268\n",
      "Epoch 254/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7809 - val_loss: 0.6201 - val_accuracy: 0.6983\n",
      "Epoch 255/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7739 - val_loss: 0.5590 - val_accuracy: 0.7709\n",
      "Epoch 256/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7711 - val_loss: 0.4945 - val_accuracy: 0.8268\n",
      "Epoch 257/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7739 - val_loss: 0.4415 - val_accuracy: 0.8324\n",
      "Epoch 258/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7837 - val_loss: 0.5051 - val_accuracy: 0.8045\n",
      "Epoch 259/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7949 - val_loss: 0.4409 - val_accuracy: 0.8324\n",
      "Epoch 260/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7949 - val_loss: 0.4652 - val_accuracy: 0.8268\n",
      "Epoch 261/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7837 - val_loss: 0.4626 - val_accuracy: 0.8212\n",
      "Epoch 262/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7795 - val_loss: 0.4519 - val_accuracy: 0.8324\n",
      "Epoch 263/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7879 - val_loss: 0.5233 - val_accuracy: 0.7933\n",
      "Epoch 264/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7767 - val_loss: 0.4475 - val_accuracy: 0.8268\n",
      "Epoch 265/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7711 - val_loss: 0.4439 - val_accuracy: 0.8324\n",
      "Epoch 266/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7739 - val_loss: 0.4810 - val_accuracy: 0.8212\n",
      "Epoch 267/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7753 - val_loss: 0.5163 - val_accuracy: 0.7318\n",
      "Epoch 268/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7781 - val_loss: 0.4869 - val_accuracy: 0.7877\n",
      "Epoch 269/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7823 - val_loss: 0.4446 - val_accuracy: 0.8436\n",
      "Epoch 270/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7837 - val_loss: 0.4992 - val_accuracy: 0.7933\n",
      "Epoch 271/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7893 - val_loss: 0.4404 - val_accuracy: 0.8380\n",
      "Epoch 272/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7823 - val_loss: 0.4346 - val_accuracy: 0.8380\n",
      "Epoch 273/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7767 - val_loss: 0.4449 - val_accuracy: 0.8268\n",
      "Epoch 274/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7725 - val_loss: 0.4450 - val_accuracy: 0.8324\n",
      "Epoch 275/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7921 - val_loss: 0.4803 - val_accuracy: 0.8212\n",
      "Epoch 276/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.8006 - val_loss: 0.5172 - val_accuracy: 0.7933\n",
      "Epoch 277/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7753 - val_loss: 0.4520 - val_accuracy: 0.8212\n",
      "Epoch 278/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7725 - val_loss: 0.4542 - val_accuracy: 0.8324\n",
      "Epoch 279/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7640 - val_loss: 0.4742 - val_accuracy: 0.8324\n",
      "Epoch 280/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.7879 - val_loss: 0.4964 - val_accuracy: 0.8156\n",
      "Epoch 281/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7767 - val_loss: 0.4369 - val_accuracy: 0.8324\n",
      "Epoch 282/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7795 - val_loss: 0.4330 - val_accuracy: 0.8380\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7795 - val_loss: 0.4747 - val_accuracy: 0.7821\n",
      "Epoch 284/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7795 - val_loss: 0.5023 - val_accuracy: 0.8045\n",
      "Epoch 285/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.8020 - val_loss: 0.4650 - val_accuracy: 0.8380\n",
      "Epoch 286/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.7753 - val_loss: 0.4541 - val_accuracy: 0.8324\n",
      "Epoch 287/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7781 - val_loss: 0.4479 - val_accuracy: 0.8268\n",
      "Epoch 288/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7921 - val_loss: 0.4405 - val_accuracy: 0.8268\n",
      "Epoch 289/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7851 - val_loss: 0.4353 - val_accuracy: 0.8045\n",
      "Epoch 290/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7837 - val_loss: 0.4466 - val_accuracy: 0.8324\n",
      "Epoch 291/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7879 - val_loss: 0.4647 - val_accuracy: 0.8045\n",
      "Epoch 292/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7767 - val_loss: 0.4781 - val_accuracy: 0.8324\n",
      "Epoch 293/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7739 - val_loss: 0.4545 - val_accuracy: 0.8212\n",
      "Epoch 294/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7823 - val_loss: 0.4586 - val_accuracy: 0.8324\n",
      "Epoch 295/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7725 - val_loss: 0.4764 - val_accuracy: 0.8324\n",
      "Epoch 296/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7823 - val_loss: 0.4575 - val_accuracy: 0.8324\n",
      "Epoch 297/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7711 - val_loss: 0.4651 - val_accuracy: 0.8436\n",
      "Epoch 298/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7935 - val_loss: 0.4755 - val_accuracy: 0.8212\n",
      "Epoch 299/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7879 - val_loss: 0.4618 - val_accuracy: 0.8212\n",
      "Epoch 300/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7879 - val_loss: 0.4554 - val_accuracy: 0.8268\n",
      "Epoch 301/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7739 - val_loss: 0.4427 - val_accuracy: 0.8380\n",
      "Epoch 302/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7837 - val_loss: 0.4512 - val_accuracy: 0.8380\n",
      "Epoch 303/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7767 - val_loss: 0.4740 - val_accuracy: 0.8324\n",
      "Epoch 304/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.7767 - val_loss: 0.4819 - val_accuracy: 0.8324\n",
      "Epoch 305/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7739 - val_loss: 0.5172 - val_accuracy: 0.7821\n",
      "Epoch 306/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7753 - val_loss: 0.5052 - val_accuracy: 0.7654\n",
      "Epoch 307/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7767 - val_loss: 0.4565 - val_accuracy: 0.8324\n",
      "Epoch 308/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8062 - val_loss: 0.4406 - val_accuracy: 0.8380\n",
      "Epoch 309/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7879 - val_loss: 0.4441 - val_accuracy: 0.8324\n",
      "Epoch 310/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7781 - val_loss: 0.4521 - val_accuracy: 0.8212\n",
      "Epoch 311/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7711 - val_loss: 0.4853 - val_accuracy: 0.8212\n",
      "Epoch 312/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7851 - val_loss: 0.4428 - val_accuracy: 0.8324\n",
      "Epoch 313/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7851 - val_loss: 0.5669 - val_accuracy: 0.7654\n",
      "Epoch 314/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7767 - val_loss: 0.5014 - val_accuracy: 0.7654\n",
      "Epoch 315/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.8212\n",
      "Epoch 316/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7949 - val_loss: 0.4392 - val_accuracy: 0.8156\n",
      "Epoch 317/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.8062 - val_loss: 0.5193 - val_accuracy: 0.7933\n",
      "Epoch 318/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7907 - val_loss: 0.4991 - val_accuracy: 0.8212\n",
      "Epoch 319/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7795 - val_loss: 0.4720 - val_accuracy: 0.8324\n",
      "Epoch 320/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7781 - val_loss: 0.4480 - val_accuracy: 0.8324\n",
      "Epoch 321/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7725 - val_loss: 0.4427 - val_accuracy: 0.8268\n",
      "Epoch 322/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7949 - val_loss: 0.4477 - val_accuracy: 0.8324\n",
      "Epoch 323/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7837 - val_loss: 0.5124 - val_accuracy: 0.7933\n",
      "Epoch 324/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7879 - val_loss: 0.4731 - val_accuracy: 0.8212\n",
      "Epoch 325/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7725 - val_loss: 0.4560 - val_accuracy: 0.8380\n",
      "Epoch 326/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7865 - val_loss: 0.4648 - val_accuracy: 0.8380\n",
      "Epoch 327/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7837 - val_loss: 0.4718 - val_accuracy: 0.8436\n",
      "Epoch 328/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7865 - val_loss: 0.4776 - val_accuracy: 0.8101\n",
      "Epoch 329/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.7781 - val_loss: 0.4477 - val_accuracy: 0.8268\n",
      "Epoch 330/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7963 - val_loss: 0.4944 - val_accuracy: 0.8045\n",
      "Epoch 331/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7865 - val_loss: 0.4584 - val_accuracy: 0.8101\n",
      "Epoch 332/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7739 - val_loss: 0.4456 - val_accuracy: 0.8324\n",
      "Epoch 333/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7767 - val_loss: 0.4837 - val_accuracy: 0.7877\n",
      "Epoch 334/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7851 - val_loss: 0.4503 - val_accuracy: 0.8324\n",
      "Epoch 335/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7851 - val_loss: 0.5770 - val_accuracy: 0.7598\n",
      "Epoch 336/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7851 - val_loss: 0.4703 - val_accuracy: 0.8324\n",
      "Epoch 337/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7963 - val_loss: 0.4423 - val_accuracy: 0.8324\n",
      "Epoch 338/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7809 - val_loss: 0.4618 - val_accuracy: 0.8268\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7823 - val_loss: 0.4617 - val_accuracy: 0.8324\n",
      "Epoch 340/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7907 - val_loss: 0.4581 - val_accuracy: 0.8212\n",
      "Epoch 341/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7739 - val_loss: 0.4674 - val_accuracy: 0.8268\n",
      "Epoch 342/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7879 - val_loss: 0.4599 - val_accuracy: 0.8324\n",
      "Epoch 343/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7851 - val_loss: 0.4687 - val_accuracy: 0.8212\n",
      "Epoch 344/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7809 - val_loss: 0.4601 - val_accuracy: 0.8268\n",
      "Epoch 345/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7851 - val_loss: 0.4648 - val_accuracy: 0.8268\n",
      "Epoch 346/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7851 - val_loss: 0.5001 - val_accuracy: 0.7821\n",
      "Epoch 347/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7711 - val_loss: 0.4525 - val_accuracy: 0.8324\n",
      "Epoch 348/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7907 - val_loss: 0.5345 - val_accuracy: 0.7095\n",
      "Epoch 349/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7711 - val_loss: 0.4996 - val_accuracy: 0.7989\n",
      "Epoch 350/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7893 - val_loss: 0.4313 - val_accuracy: 0.8380\n",
      "Epoch 351/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7781 - val_loss: 0.4474 - val_accuracy: 0.8324\n",
      "Epoch 352/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7823 - val_loss: 0.4492 - val_accuracy: 0.8324\n",
      "Epoch 353/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7949 - val_loss: 0.4661 - val_accuracy: 0.8324\n",
      "Epoch 354/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7865 - val_loss: 0.5069 - val_accuracy: 0.7877\n",
      "Epoch 355/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7851 - val_loss: 0.4542 - val_accuracy: 0.8324\n",
      "Epoch 356/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7893 - val_loss: 0.5160 - val_accuracy: 0.7933\n",
      "Epoch 357/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7683 - val_loss: 0.4899 - val_accuracy: 0.8156\n",
      "Epoch 358/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7683 - val_loss: 0.4394 - val_accuracy: 0.8324\n",
      "Epoch 359/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7809 - val_loss: 0.4929 - val_accuracy: 0.7821\n",
      "Epoch 360/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.7598 - val_loss: 0.5176 - val_accuracy: 0.7486\n",
      "Epoch 361/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7907 - val_loss: 0.4476 - val_accuracy: 0.8324\n",
      "Epoch 362/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7851 - val_loss: 0.5145 - val_accuracy: 0.7877\n",
      "Epoch 363/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7823 - val_loss: 0.5593 - val_accuracy: 0.7709\n",
      "Epoch 364/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7907 - val_loss: 0.4456 - val_accuracy: 0.8212\n",
      "Epoch 365/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7837 - val_loss: 0.4807 - val_accuracy: 0.7709\n",
      "Epoch 366/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7753 - val_loss: 0.5121 - val_accuracy: 0.7654\n",
      "Epoch 367/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7851 - val_loss: 0.4381 - val_accuracy: 0.8324\n",
      "Epoch 368/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7823 - val_loss: 0.4656 - val_accuracy: 0.8324\n",
      "Epoch 369/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7823 - val_loss: 0.4985 - val_accuracy: 0.8268\n",
      "Epoch 370/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7893 - val_loss: 0.4844 - val_accuracy: 0.8268\n",
      "Epoch 371/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7907 - val_loss: 0.5234 - val_accuracy: 0.7933\n",
      "Epoch 372/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7837 - val_loss: 0.4849 - val_accuracy: 0.8101\n",
      "Epoch 373/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7640 - val_loss: 0.4526 - val_accuracy: 0.8324\n",
      "Epoch 374/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7753 - val_loss: 0.4431 - val_accuracy: 0.8380\n",
      "Epoch 375/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7823 - val_loss: 0.5055 - val_accuracy: 0.8045\n",
      "Epoch 376/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7767 - val_loss: 0.4728 - val_accuracy: 0.8268\n",
      "Epoch 377/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7879 - val_loss: 0.4692 - val_accuracy: 0.8324\n",
      "Epoch 378/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7781 - val_loss: 0.5394 - val_accuracy: 0.7877\n",
      "Epoch 379/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7837 - val_loss: 0.4706 - val_accuracy: 0.8324\n",
      "Epoch 380/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7935 - val_loss: 0.4705 - val_accuracy: 0.7877\n",
      "Epoch 381/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7697 - val_loss: 0.5319 - val_accuracy: 0.7821\n",
      "Epoch 382/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7739 - val_loss: 0.4679 - val_accuracy: 0.8324\n",
      "Epoch 383/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7837 - val_loss: 0.4766 - val_accuracy: 0.8212\n",
      "Epoch 384/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7697 - val_loss: 0.4799 - val_accuracy: 0.8268\n",
      "Epoch 385/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7949 - val_loss: 0.5090 - val_accuracy: 0.8101\n",
      "Epoch 386/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7711 - val_loss: 0.4708 - val_accuracy: 0.8268\n",
      "Epoch 387/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7767 - val_loss: 0.4675 - val_accuracy: 0.8268\n",
      "Epoch 388/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7893 - val_loss: 0.6848 - val_accuracy: 0.6145\n",
      "Epoch 389/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7697 - val_loss: 0.4666 - val_accuracy: 0.8268\n",
      "Epoch 390/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.7697 - val_loss: 0.4672 - val_accuracy: 0.8156\n",
      "Epoch 391/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.7654 - val_loss: 0.5683 - val_accuracy: 0.7654\n",
      "Epoch 392/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7753 - val_loss: 0.4782 - val_accuracy: 0.8268\n",
      "Epoch 393/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7683 - val_loss: 0.4995 - val_accuracy: 0.8268\n",
      "Epoch 394/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7795 - val_loss: 0.4576 - val_accuracy: 0.8324\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7851 - val_loss: 0.4857 - val_accuracy: 0.8156\n",
      "Epoch 396/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.7739 - val_loss: 0.4791 - val_accuracy: 0.8268\n",
      "Epoch 397/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.7472 - val_loss: 0.6493 - val_accuracy: 0.6760\n",
      "Epoch 398/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7907 - val_loss: 0.4767 - val_accuracy: 0.7989\n",
      "Epoch 399/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7907 - val_loss: 0.4783 - val_accuracy: 0.8324\n",
      "Epoch 400/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7851 - val_loss: 0.4478 - val_accuracy: 0.8324\n",
      "Epoch 401/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7767 - val_loss: 0.4726 - val_accuracy: 0.8268\n",
      "Epoch 402/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7851 - val_loss: 0.5156 - val_accuracy: 0.7821\n",
      "Epoch 403/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7837 - val_loss: 0.4681 - val_accuracy: 0.8324\n",
      "Epoch 404/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7753 - val_loss: 0.4741 - val_accuracy: 0.8380\n",
      "Epoch 405/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7865 - val_loss: 0.4668 - val_accuracy: 0.8324\n",
      "Epoch 406/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.8006 - val_loss: 0.5058 - val_accuracy: 0.7598\n",
      "Epoch 407/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7851 - val_loss: 0.6204 - val_accuracy: 0.6536\n",
      "Epoch 408/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7711 - val_loss: 0.4339 - val_accuracy: 0.8380\n",
      "Epoch 409/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7851 - val_loss: 0.5334 - val_accuracy: 0.7877\n",
      "Epoch 410/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7654 - val_loss: 0.4707 - val_accuracy: 0.7933\n",
      "Epoch 411/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7697 - val_loss: 0.4553 - val_accuracy: 0.8324\n",
      "Epoch 412/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7767 - val_loss: 0.4961 - val_accuracy: 0.8212\n",
      "Epoch 413/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7781 - val_loss: 0.4637 - val_accuracy: 0.8212\n",
      "Epoch 414/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7865 - val_loss: 0.4842 - val_accuracy: 0.8268\n",
      "Epoch 415/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7851 - val_loss: 0.4537 - val_accuracy: 0.8324\n",
      "Epoch 416/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7851 - val_loss: 0.5002 - val_accuracy: 0.7989\n",
      "Epoch 417/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7879 - val_loss: 0.4541 - val_accuracy: 0.8156\n",
      "Epoch 418/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7879 - val_loss: 0.4325 - val_accuracy: 0.8324\n",
      "Epoch 419/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7921 - val_loss: 0.5659 - val_accuracy: 0.7709\n",
      "Epoch 420/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7640 - val_loss: 0.5490 - val_accuracy: 0.7542\n",
      "Epoch 421/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7781 - val_loss: 0.4722 - val_accuracy: 0.8324\n",
      "Epoch 422/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7809 - val_loss: 0.5005 - val_accuracy: 0.7989\n",
      "Epoch 423/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7879 - val_loss: 0.4376 - val_accuracy: 0.8380\n",
      "Epoch 424/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7781 - val_loss: 0.4347 - val_accuracy: 0.8324\n",
      "Epoch 425/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7837 - val_loss: 0.4744 - val_accuracy: 0.8101\n",
      "Epoch 426/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7823 - val_loss: 0.4364 - val_accuracy: 0.8324\n",
      "Epoch 427/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7921 - val_loss: 0.4619 - val_accuracy: 0.8268\n",
      "Epoch 428/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7837 - val_loss: 0.4334 - val_accuracy: 0.8268\n",
      "Epoch 429/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7851 - val_loss: 0.4701 - val_accuracy: 0.8212\n",
      "Epoch 430/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7978 - val_loss: 0.4415 - val_accuracy: 0.8324\n",
      "Epoch 431/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7907 - val_loss: 0.6094 - val_accuracy: 0.6536\n",
      "Epoch 432/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7697 - val_loss: 0.4634 - val_accuracy: 0.8268\n",
      "Epoch 433/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7935 - val_loss: 0.4442 - val_accuracy: 0.8324\n",
      "Epoch 434/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7767 - val_loss: 0.5039 - val_accuracy: 0.7933\n",
      "Epoch 435/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7809 - val_loss: 0.5049 - val_accuracy: 0.8268\n",
      "Epoch 436/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7767 - val_loss: 0.4689 - val_accuracy: 0.8268\n",
      "Epoch 437/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.7683 - val_loss: 0.4615 - val_accuracy: 0.8101\n",
      "Epoch 438/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7725 - val_loss: 0.4455 - val_accuracy: 0.8324\n",
      "Epoch 439/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7725 - val_loss: 0.4420 - val_accuracy: 0.8268\n",
      "Epoch 440/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7683 - val_loss: 0.4875 - val_accuracy: 0.8101\n",
      "Epoch 441/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7640 - val_loss: 0.4690 - val_accuracy: 0.8324\n",
      "Epoch 442/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7935 - val_loss: 0.4430 - val_accuracy: 0.8324\n",
      "Epoch 443/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7921 - val_loss: 0.5045 - val_accuracy: 0.7933\n",
      "Epoch 444/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7921 - val_loss: 0.5111 - val_accuracy: 0.7877\n",
      "Epoch 445/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7893 - val_loss: 0.4475 - val_accuracy: 0.8324\n",
      "Epoch 446/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7725 - val_loss: 0.5026 - val_accuracy: 0.7877\n",
      "Epoch 447/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7781 - val_loss: 0.4889 - val_accuracy: 0.8156\n",
      "Epoch 448/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7767 - val_loss: 0.4506 - val_accuracy: 0.8212\n",
      "Epoch 449/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7935 - val_loss: 0.4511 - val_accuracy: 0.8324\n",
      "Epoch 450/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7851 - val_loss: 0.4664 - val_accuracy: 0.8324\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7739 - val_loss: 0.4542 - val_accuracy: 0.8324\n",
      "Epoch 452/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7809 - val_loss: 0.4607 - val_accuracy: 0.8268\n",
      "Epoch 453/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7739 - val_loss: 0.4794 - val_accuracy: 0.8268\n",
      "Epoch 454/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7823 - val_loss: 0.6156 - val_accuracy: 0.7151\n",
      "Epoch 455/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7879 - val_loss: 0.4849 - val_accuracy: 0.8101\n",
      "Epoch 456/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7851 - val_loss: 0.5122 - val_accuracy: 0.7821\n",
      "Epoch 457/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7893 - val_loss: 0.4912 - val_accuracy: 0.8268\n",
      "Epoch 458/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7865 - val_loss: 0.4534 - val_accuracy: 0.8268\n",
      "Epoch 459/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7612 - val_loss: 0.4729 - val_accuracy: 0.8324\n",
      "Epoch 460/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7893 - val_loss: 0.4441 - val_accuracy: 0.8380\n",
      "Epoch 461/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7781 - val_loss: 0.4382 - val_accuracy: 0.8268\n",
      "Epoch 462/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7570 - val_loss: 0.4818 - val_accuracy: 0.8324\n",
      "Epoch 463/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7879 - val_loss: 0.4525 - val_accuracy: 0.8268\n",
      "Epoch 464/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7711 - val_loss: 0.4815 - val_accuracy: 0.8324\n",
      "Epoch 465/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7725 - val_loss: 0.5151 - val_accuracy: 0.7933\n",
      "Epoch 466/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7683 - val_loss: 0.4300 - val_accuracy: 0.8380\n",
      "Epoch 467/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7823 - val_loss: 0.4755 - val_accuracy: 0.8324\n",
      "Epoch 468/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7865 - val_loss: 0.4779 - val_accuracy: 0.8324\n",
      "Epoch 469/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7851 - val_loss: 0.4871 - val_accuracy: 0.7654\n",
      "Epoch 470/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7865 - val_loss: 0.5117 - val_accuracy: 0.7821\n",
      "Epoch 471/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7837 - val_loss: 0.4501 - val_accuracy: 0.8268\n",
      "Epoch 472/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.8268\n",
      "Epoch 473/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.8268\n",
      "Epoch 474/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7809 - val_loss: 0.5054 - val_accuracy: 0.8268\n",
      "Epoch 475/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7837 - val_loss: 0.4993 - val_accuracy: 0.8268\n",
      "Epoch 476/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7781 - val_loss: 0.4920 - val_accuracy: 0.8212\n",
      "Epoch 477/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7907 - val_loss: 0.4461 - val_accuracy: 0.8324\n",
      "Epoch 478/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7781 - val_loss: 0.5433 - val_accuracy: 0.7933\n",
      "Epoch 479/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7851 - val_loss: 0.4768 - val_accuracy: 0.8324\n",
      "Epoch 480/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7907 - val_loss: 0.4888 - val_accuracy: 0.8156\n",
      "Epoch 481/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7837 - val_loss: 0.4925 - val_accuracy: 0.8268\n",
      "Epoch 482/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7893 - val_loss: 0.5187 - val_accuracy: 0.7877\n",
      "Epoch 483/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7851 - val_loss: 0.4536 - val_accuracy: 0.8324\n",
      "Epoch 484/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7837 - val_loss: 0.4467 - val_accuracy: 0.8324\n",
      "Epoch 485/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7711 - val_loss: 0.4395 - val_accuracy: 0.8380\n",
      "Epoch 486/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7725 - val_loss: 0.4740 - val_accuracy: 0.8268\n",
      "Epoch 487/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7739 - val_loss: 0.4499 - val_accuracy: 0.8380\n",
      "Epoch 488/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7767 - val_loss: 0.5527 - val_accuracy: 0.7877\n",
      "Epoch 489/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7963 - val_loss: 0.4685 - val_accuracy: 0.8324\n",
      "Epoch 490/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7865 - val_loss: 0.4817 - val_accuracy: 0.8268\n",
      "Epoch 491/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7823 - val_loss: 0.4969 - val_accuracy: 0.8212\n",
      "Epoch 492/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7823 - val_loss: 0.4660 - val_accuracy: 0.8268\n",
      "Epoch 493/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7781 - val_loss: 0.4600 - val_accuracy: 0.8268\n",
      "Epoch 494/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7669 - val_loss: 0.4852 - val_accuracy: 0.8324\n",
      "Epoch 495/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7907 - val_loss: 0.4589 - val_accuracy: 0.8268\n",
      "Epoch 496/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7879 - val_loss: 0.5214 - val_accuracy: 0.8101\n",
      "Epoch 497/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7837 - val_loss: 0.4743 - val_accuracy: 0.8268\n",
      "Epoch 498/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7879 - val_loss: 0.4608 - val_accuracy: 0.8268\n",
      "Epoch 499/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7669 - val_loss: 0.5424 - val_accuracy: 0.7877\n",
      "Epoch 500/500\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7753 - val_loss: 0.4677 - val_accuracy: 0.8268\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y,\n",
    "                   batch_size=5,\n",
    "                   epochs=500,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=history.history['accuracy']\n",
    "loss=history.history['loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label=\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(model.predict(test)).argmax(axis=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = load_titanic_data(\"gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = submission_data.drop(columns=[\"Age\", \"Fare\", \"Parch\", \"Pclass\", \"SibSp\", \"Female\", \"Male\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId\n",
       "0          892\n",
       "1          893\n",
       "2          894\n",
       "3          895\n",
       "4          896"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
